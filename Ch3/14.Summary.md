本章我们学习了更多用TensorFlow作为库表达和训练机器学习模型，讨论了TensorFlow的许多重要特性，包括会话的管理，变量，运算，计算图和设备。在最后一节，我们用这些理解训练和可视化了一个逻辑回归模型和用随机梯度下降的前馈神经网络。尽管逻辑网络在MNIST数据集上产生很多错误，但前馈网络表现的更加高效，每100个数字仅有平均1.8个错误。在第5章我们会进一步改善这个错误率。

在下一章，我们将开始应对加深网络时出现的各种问题。我们已经探讨了第一个难题，就是找到更加精致的方式初始化网络参数。在下一章，我们会发现随着模型越来越复杂，精致的初始化不再足以达到好的性能。为了克服这些挑战，我们将深入钻研现代优化理论，为训练深度模型设计更好的算法。
