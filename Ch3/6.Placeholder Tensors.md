## 占位符
现在我们对TensorFlow变量和运算已经有了扎实的理解，几乎完整描述了TensorFlow计算图的成分。唯一疏漏的是我们如何把输入传到深度模型(在训练和测试阶段)。由于变量只意味着初始化一次，因此它是不能胜任的。反而，我们需要每一次计算图运行时都存在的成分。

TensorFlow用一种叫做占位符的结构解决了这个问题 $^{12}$。占位符用下面的代码实例化，就像一般的TensorFlow变量和张量，可以用在运算中。

```
x = tf.placeholder(tf.float32, name="x", shape=[None, 784])
W = tf.Variable(tf.random_uniform([784,10], -1, 1), name="W")
multiply = tf.matmul(x, W)
```

此处定义占位符x， 表示以float32格式存储的小批量数据。我们注意到x有784列，这意味着每个数据采样有784维。同样我们也注意到x有未定义数量的行，这表明x可以用任意数目的数据采样初始化。我们可以把整个小批量数据表示为张量，并行计算所有数据采样的结果，以此来代替用W单独乘以每个数据采样。结果是multiply张量的第i行对应W乘以第i个数据采样。

就像变量需要在第一次创建计算图时初始化一样，占位符也需要在每一次计算图(或者子图)运行时填充。下一节我们将详细讨论这个工作机制。

> 12 https://www.tensorflow.org/api_docs/python/tf/placeholder
