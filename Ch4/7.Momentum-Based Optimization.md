## 基于动量的优化
从根本上，病态海森矩阵问题体现在自身以梯度的形式剧烈波动。因此，一种对付病态的流行机制是忽略海森的计算，而是聚焦在如何对消训练过程中的这些波动。

如何解决这个问题的一种方法是研究球如何滚下山坡。由于重力驱动，球最终稳定在曲面的最小值，但由于某些原因，它并不像梯度下降时会剧烈的波动和偏离。为什么会这样？与随机梯度下降(仅使用梯度)不同，有两种主要因素决定了球如何滚下误差曲面。第一个因素是通常所说的加速度，我们在SGD中已经建模为梯度。但加速度并不能凭一己之力决定球的运动。反而速度更直接地决定了它的运动。加速度只是通过修正速度来间接地改变球的位置。

速度驱动的运动是令人满意的，因为它通过平滑球的历史轨迹，对消剧烈波动梯度的影响。速度作为一种记忆形式，对消正交方向振荡加速度，允许更有效地在最小值方向上积累运动。我们的目标是在优化算法中以某种方式产生速度的模拟。可以通过跟踪过去梯度的指数加权衰减来做到这一点。前提很简单：每次更新都是联合最后一次迭代的更新和当前梯度来计算。具体地说，按如下公式计算参数向量的变化：

$$
v_i = mv_{i-1} - \epsilon g_i \\
\theta_i = \theta_{i-1} + v_i
$$

换句话说，我们用动量超参数 $m$ 确定先前的速度有多少要保留在新的更新，把过去梯度的这部分记忆加到当前梯度。这种方法通常被称为动量 $^4$。因为动量项增加了步进的大小，与普通随机梯度下降相比，使用动量需要更小的学习率。

为了更好地可视化动量如何工作，我们将探讨一个简单的例子。特别地，研究在随机行走中动量如何影响更新。随机行走是一连串随机选择的步进。在我们的例子中，想象直线上的一颗粒子，在每个时间间隔在-10和10之间随机选择步进大小，并在该方向上移动。这可简单地表示为：

```
step_range = 10
step_range = 10step_choices = range(-1 * step_range,
                                         step_range + 1)
rand_walk = [random.choice(step_choices) for x in xrange(100)]
```

然后模拟用动量稍加修正(即标准的指数加权移动平均算法)去平滑每个时间间隔步进选择会发生什么。再次，可以简洁地表达模拟过程为：

```
momentum_rand_walk = [random.choice(step_choices)]
for i in xrange(len(rand_walk) - 1):
    prev = momentum_rand_walk[-1]
    rand_choice = random.choice(step_choices)
    new_step = momentum * prev + (1 - momentum) * rand_choice
    momentum_rand_walk.append()
```

随着从0到1变化动量，结果是惊人的。动量显著地减少了更新的波动。动量越大，对新的更新响应越慢(即在一个相当长的时期内轨迹传播的首次估计明显不精确)。试验的结果总结在图4-8。

![Momentum smooths volatility in the step sizes during a random walk using an exponentially weighted moving average](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig4-8.png?raw=true)

图4-8 Momentum smooths volatility in the step sizes during a random walk using an exponentially weighted moving average

为了研究动量实际上如何影响前馈神经网络的训练，我们可以用TensorFlow动量优化器重新训练可靠的MNIST前馈网络。本例中我们可以使用相同的学习率(0.01)和典型动量值0.9：

```
learning_rate = 0.01
momentum = 0.9
optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)
train_op = optimizer.minimize(cost, global_step=global_step)
```

加速的结果是明显的。比较图4-9的TensorBoard可视化结果，我们展示了代价函数如何随时间变化。图像显示为了达到0.1的代价，没有动量(左)需要将近18000次步进(小批量)，而有动量(右)的只需要2000多次。

![Comparing training a feed-forward network with (right) and without (left) momentum demonstrates a massive decrease in training time](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig4-9.png?raw=true)

图4-9 Comparing training a feed-forward network with (right) and without (left) momentum demonstrates a massive decrease in training time

最近，开展了更多的工作探索如何改善经典的动量技术。2013年Sutskever等人提出了一种叫Nesterov动量的改进方案，它在更新速度时不在误差曲面的 $\theta$ 上，而是在 $\theta + v_{i-1}$ 上计算梯度 $^5$。这个细小的差别似乎允许Nesterov动量以更反应灵敏的方式改变速度。实验表明这种方法在批量梯度下降中有明显的好处(保证收敛，与经典动量相比对指定学习率能够使用更高的动量)，但对在大多数深度学习优化方法中使用的随机小批量梯度下降，这种方法是否奏效并不完全明朗。在本书撰写之际，TensorFlow尚未有对Nerestov动量开箱即用的支持。

> 4 Polyak, Boris T. “Some methods of speeding up the convergence of iteration methods.” USSR Computational Mathematics and Mathematical Physics 4.5 (1964): 1-17.

> 5 Sutskever, Ilya, et al. “On the importance of initialization and momentum in deep learning.” ICML (3) 28(2013): 1139-1147.
