尽管理论上可能，但现实中极难达到那种通用性。困难来源于面对的RNN可能的架构和参数值的巨大搜索空间的事实，这个空间对梯度下降寻找任何随意问题的合适解来说过于庞大。然而，在本章接下来的小节，我们要开始探索一些研究前沿的方法去唤醒RNN蕴藏的潜能。

让我们想一想一个下面这样的非常简单的阅读理解问题：

Mary travelled to the hallway. She **grabbed the milk glass** there.  
Then she travelled to the office, where she found an apple  
and **grabbed it**.  
How many objects is Mary carrying?

答案很简答：2个。但大脑里发生了什么使得我们如此轻松地给出答案？如果我们考虑如何用简单的计算机程序来解决这个理解问题，方法可能如下：
```
1. 为计算器counter分配内存位置
2. 初始化计算器counter为0
3. for each word in passage
   3.1. if word is 'grabbed'
       3.1.1. increment counter
4. return counter value
```
