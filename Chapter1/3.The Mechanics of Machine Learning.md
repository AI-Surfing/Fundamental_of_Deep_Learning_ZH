## 机器学习机理
为了解决这些问题，我们必须要使用全新的方法。在学校的岁月里，我们学习的很多东西与传统计算机程序是一样的。我们学习如何乘数，解方程，通过消化理解一堆规则求导数。但是我们小时候学到的最自然的东西都是通过例子学会的，而不是公式。

例如，在我们两岁的时候，父母并没有教我们如何通过量鼻子的形状或者身体的外形来识别小狗。我们通过多个示范的实例和认错了就纠正来学会识别小狗。换句话说，当我们出生时，大脑给我们提供了如何能够观察世界的模型。随着逐渐长大，模型吸收我们的感官输入，对我们所经历的进行猜测。如果猜测得到了父母的确认，模型会被强化。如果父母说我们猜错了，我们将会修正模型来包含这个新的信息。在一生当中，随着理解消化越来越多的实例，我们的模型变得越来越准确。显然所有这些活动都是下意识进行的，我们甚至都没有意识到，不过这个能力使我们更有优势。

机器学习是人工智能更加普通化的领域，它基于实例学习来实现预测，深度学习是机器学习的一个分支。在机器学习中，不再用一大堆规则来指示计算机解决问题，而是提供一个可以评估实例的模型和指导计算机计算错误时修正模型的少量指令。我们期望随着时间的流逝，适当的模型将能够非常准确地解决问题。

我们把这个思想数学化，更加严谨地阐述它的涵义。把模型定义为函数$h(x,\theta)$。输入$x$是用向量表示的实例。例如图1-3所示，如果$x$是灰度图像，向量的每一项代表每个位置的像素亮度。

![The process of vectorizing an image for a machine learning algorithm](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig1-3.png?raw=true)    

图1-3 The process of vectorizing an image for a machine learning algorithm

输入 $\theta$ 是模型的参数向量。随着学习的实例越来越多，机器学习程序努力去优化这些参数的取值。我们将在实战中观察参数优化过程，更多的细节详见第二章。

为了更加直观理解机器学习模型，我们来剖析一个简单的例子。假设我们想确定基于前一晚的学习时长和睡眠时长如何预测考试效果。我们收集大量的数据，对每个数据点 $x=[x_1, x_2]^T$，我们用$x_1$记录睡眠时长，$x_2$是花费在学习上的时长，还记录考试结果是否高于或低于班级平均水平。我们的目标是用参数向量 $\theta = [\theta_0$ $\theta_1$ $\theta_2]^T$学习到如下的模型$h(x, \theta)$：

$$
h(x,\theta)=\left\{\begin{matrix}
-1, & if \quad x^T\cdot \begin{bmatrix}
\theta_1 \\
\theta_2 \\
\end{bmatrix}
+ \theta_0 < 0 \\\
1, & if \quad x^T\cdot \begin{bmatrix}
\theta_1 \\
\theta_2 \\
\end{bmatrix}
+ \theta_0 \geq  0
\end{matrix}\right.
$$

换句话说，我们假设模型$h(x, \theta)$ 的设计图如上所述(在几何上，这个特别的设计图描绘了一个线性分类器，将坐标面分为两半)。然后，我们训练参数向量 $\theta$，使得模型对给定输入实例$x$做出正确的预测(如果考试结果在平均分以下为1，否则为-1)。该模型称为线性感知机，从二十世纪五十年代开始就已经使用了。假设数据如图1-4所示。

![Sample data for our exam predictor algorithm and a potential classifier](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig1-4.png?raw=true)  

图1-4 Sample data for our exam predictor algorithm and a potential classifier

结果显示，令 $\theta=[-24$ $3$ $4]^T$，我们的机器学习模型在每个数据点上都做出正确的预测：

$$
h(x,\theta)=\left\{\begin{matrix}
-1, & if \quad 3x_1 + 4x_2 - 24 < 0 \\\
1, & if \quad 3x_1 + 4x_2 - 24 \geq  0
\end{matrix}\right.
$$

最优参数向量 $\theta$ 确定分类器的位置使得我们能够做出尽可能多的正确预测。在大部分情况下，$\theta$的最优解有很多种选择(甚至是无穷多种)。但幸运的是，大部分情况下这些最优解彼此间如此相近，它们之间的差异几乎可以忽略不计。如果事实并非如此，那我们则要收集更多的数据来缩小 $\theta$ 的选择范围。

建模看起来是合理的，但仍遗留了一些相当重要的问题。首先，最开始我们怎么设法得到参数向量 $\theta$ 的最优值？解决整个问题需要众所周知的优化技术。优化器的目标是通过迭代调整参数直到误差最小化来最优化机器学习模型的性能。当在第二章更加详细地描述梯度下降过程时，我们将着手开始处理训练参数向量的问题。在后面的章节，我们将努力去寻找使这个过程更加高效的方法。

其次，显然这个特殊的模型(线性感知机模型)能够学习到的关系非常有限。例如，如图1-5所示的数据分布就不能用线性感知机很好地描述。

![As our data takes on more complex forms, we need more complex models to describe them](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig1-5.png?raw=true)

图1-5 As our data takes on more complex forms, we need more complex models to describe them

但是这些情况仅仅是冰山一角。当我们转向更加复杂的问题时，如目标识别和文本分析，数据维度极其高，需要挖掘的关系也变得高度非线性。为了适应这样的复杂性，近期的机器学习研究已经尝试创建类似于人脑结构的模型。这项研究的主体本质上就是俗称的深度学习，它在处理计算机视觉和自然语言处理等问题上已经取得了令人瞩目的成绩。这些算法不仅远超其他类型的机器学习算法，而且达到(甚至超过了)人类的认知准确度。
