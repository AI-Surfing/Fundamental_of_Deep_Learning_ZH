## 神经元
人脑的基本单元是神经元。一片小小的大脑，大约稻粒那么大，包含10000多个神经元，每个神经元与其他神经元形成平均6000个连接。正是这个庞大的生物网络使得我们可以感知周围的世界。本节的目标是用这个自然的结构创建机器学习模型，用与大脑类似的方式解决问题。

神经元的核心部位进化后可以接收来自其他神经元的信息，并用独特的方式处理，然后把处理结果传送给其他细胞。处理过程总结在图1-6。神经元沿着天线状结构的树状突(dendrites)接收输入，每个输入连接根据使用多久动态地增强或减弱(这就是我们如何学习新概念的原理！)，每个连接的强度决定了输入对神经元输出的贡献。在被各自连接强度加权后，在细胞体中把输入累加起来。然后累加和被变换成新的信号沿着细胞的轴突(axon)发送到其他神经元。

![](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig1-6.png)

图1-6 A functional description of a biological neuron's structure

我们能够把对大脑中神经元的功能性理解转变成可用计算机表示的人工模型。图1-7描述了这样的模型，改善了1943年Warren S. McCulloch和Walter H. Pitts首次提出的方法。正如在生物神经元一样，我们的人工神经元接收一定数量的输入，$x_1, x_2,...,x_n$，每个输入乘以指定的权重， $w_1,w_2,...,w_n$。如前所述，加权后的输入相加生成神经元的logit，$z=\sum_{i=0}^{n}w_ix_i$。在很多场合中，logit还包括一个常量-偏置(图中没有表示)。logit通过函数$f$产生输出 $y=f(z)$，它可以被发送到其他神经元。

![](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig1-7.png)

图1-7 Schematic for a neuron in an artificial neural net

通过再次用向量形式表示，我们来结束人工神经元功能的数学讨论。将输入重新用向量形式表示为 $x=[x_1 \ x_2 \ ... \ x_n]$，神经元权重重新表示为 $w=[w1 \ w2 \ ... \ w_n]$。然后神经元输出重新表示为 $y=f(x \cdot w+b)$，其中 $b$ 是偏置项。换句话说，我们可以用输入和加权向量的点积计算输出，然后加上偏置项生成logit，再应用变换函数。尽管这看起来似乎是普通的重写，但把神经元视为向量操作系列将对在本书后续章节用软件实现神经元至关重要。
