## 前馈神经网络
尽管单个神经元比线性感知机更加强大，但表达能力还远不足以解决复杂的学习问题，这是我们大脑由不止一个神经元组成的原因。例如，单个神经元不可能区分开手写的数字。为了处理更加负载的任务，我们必须进一步优化机器学习模型。

大脑中的神经元是分层构成的。事实上，大脑皮质(负载人类大部分智商的结构)由6层组成 [^7] 。信息流从一层到另一层直到感觉输入被转化为概念性理解。例如，视觉皮质末端层从眼睛接收原始的视觉数据，经每层处理后传递到下一层，直到第六层我们推断出正在看到的是只猫，或者汽水罐，抑或是架飞机。图1-9是这些层更简化的版本。

![](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig1-9.png)

图1-9 A simple example of a feed-forward neural network with three layers (input,
one hidden, and output) and three neurons per layer

借助这些概念，我们能够构建人工神经网络。当我们开始把神经元与其他神经元、输入数据和对学习问题相当于网络答复的输出节点连接起来，就实现了神经网络。图1-9展示了一个人工神经网络的简单例子，类似于McCulloch 和Pitt 1943年工作里的架构。网络的最底层吸收输入数据，神经元最顶层(输入节点)计算最终答案。神经元的中间层称为*隐藏层*，我们令 $k^{th}$ 层的 $i^{th}$ 个神经元与 $k+1^{st}$ 层的 $j^{th}$ 个神经元之间连接的加权为 $w_{i,j}^{(k)}$。这些加权组成了参数向量 $\theta$，如前所述，神经网络解决问题的能力取决于找到最优的值填入 $\theta$。

我们注意到在这个例子中，连接仅仅从较低层横贯到较高层，同层之间的神经元之间没有连接，没有从较高层向较低层传输数据的连接。这样的神经网络叫做*前馈*网络，由于易于分析，所以从讨论前馈网络开启我们的学习之旅。我们在第二章给出前馈网络分析(即为加权选择最优值的过程)。更多复杂的连接方式将在后续章节阐述。

在最后部分，我们将讨论在前馈神经网络中使用的层的主要类型。但是在讲解之前，必须牢记一些重要内容：

1.正如我们提到的，夹在神经元第一层(输入层)和最后一层(输出层)之间的神经元层叫做隐藏层。

[^7]: Mountcastle, Vernon B. “Modality and topographic properties of single neurons of cat’s somatic sensory cortex.”
Journal of Neurophysiology 20.4 (1957): 408-434.
