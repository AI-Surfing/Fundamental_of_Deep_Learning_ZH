## 测试集，验证集和过拟合
人工神经网络一个主要的问题是模型太复杂。例如，考虑一个神经网络从MNIST数据库(28×28像素)里的图像拉取数据，输入到有30个神经元的两个隐藏层，最后到达10个神经元的softmax层。网络里总共有近25000个参数，这样是有问题的，为了明白为什么这么说，让我们看一下图2-8展示的一个新的简单案例。

![Two potential models that might describe our dataset: a linear model versus a degree 12 polynomial](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-8.png?raw=true)

图2-8 Two potential models that might describe our dataset: a linear model versus a degree 12 polynomial

我们在平面上生成了大量是数据点，目标是找到一条曲线可以最好地描述这个数据集(即，允许我们根据x坐标预测出新的数据点的y坐标)。用这些数据我们训练出两个不同的模型：一个线性模型和一个12次多项式。究竟哪条曲线值得我们信赖呢？是几乎没有预测出正确点的直线？还是预测中了数据集中每个点的复杂曲线呢？此刻我们可能相信线性拟合，因为它看起来更少勉强的味道。但为了确保我们的选择，向数据集中加入更多的数据。结果如图2-9所示。

![Evaluating our model on new data indicates that the linear fit is a much better model than the degree 12 polynomial](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-9.png?raw=true)

图2-9 Evaluating our model on new data indicates that the linear fit is a much better model than the degree 12 polynomial

现在决定已经很清楚了：线性模型不仅主观上感觉更好，而且定量分析也好(用平方差度量测量)。但这导致了一个非常有趣的关于训练和评估机器学习模型的讨论点。通过创建极其复杂的模型，非常容易完美地拟合训练数据集，因为我们可以给模型足够的自由度来扭曲它们去拟合训练集里的观察点。但当我们在新数据上评估如此复杂的模型时，它的性能表现很差。换句话说，模型泛化性能不好。这种现象我们称之为过拟合，它是机器学习工程师必须应对的巨大挑战之一。在深度学习中，神经网络有大量包含很多神经元的层，过拟合变成了甚至更加严峻的问题。这些模型里连接的数量都是天文数字，达到上百万个。因此，过拟合是普遍的。

让我们看看过拟合在神经网络里是什么样的。假设有个神经网络，两个输入，2维的softmax输出，隐藏层分别有3,6和20个神经元。用mini-batch梯度下降(batch大小为10)训练这些网络，结果用ConvNetJS可视化，如图2-10所示。

![A visualization of neural networks with 3, 6, and 20 neurons (in that order) in their hidden layer](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-10.png?raw=true)

图2-10 A visualization of neural networks with 3, 6, and 20 neurons (in that order) in their hidden layer

从这些图已经很明显看出，随着网络中连接数的增加，对数据过拟合的倾向也在增加。当我们增加神经网络深度，可以看到类似的过拟合现象。结果展示在图2-11，我们分别用1,2和4个每层含有三个神经元的隐藏层。

![A visualization of neural networks with one, two, and four hidden layers (in that order) of three neurons each](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-11.png?raw=true)

图2-11 A visualization of neural networks with one, two, and four hidden layers (in that order) of three neurons each

这产生了三点重要的观察。第一，机器学习工程师总是在过拟合和模型复杂度之间寻求直接的折中。如果模型不够复杂，可能就不会足够有效地捕捉到解决问题必须的所有有用信息。然而如果模型非常复杂(尤其是只有有限的的数据任由支配)，我们就有过拟合的风险。深度学习采用非常复杂的模型解决非常复杂的问题，同时采取额外的对策防止过拟合。在本章和后面的章节我们将看到许多这样的对策。

第二，用训练模型的数据来评估模型是个误区。用图2-8的例子，将会错误地表明12次多项式模型优于线性拟合。因此，我们几乎从来不在整个数据集上训练模型。相反，如图2-12所示，我们把数据切分为训练集和测试集。

![We often split our data into nonoverlapping training and test sets in order to fairly evaluate our model](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-12.png?raw=true)

图2-12 We often split our data into nonoverlapping training and test sets in order to fairly evaluate our model

通过直接测试模型在未见过的新数据上泛化性如何，使得我们对模型能够做出公正的评估。在现实中，很难获得大的数据集，所以在训练过程中不利用所有任由支配的数据看起来似乎有点浪费。因此，在编译测试数据时，复用训练数据用于测试或者走捷径显得非常有吸引力。需要警惕：如果没有好好地构造测试集，我们将不能得到任何关于模型的有意义的结论。

第三，当我们训练数据时，非常有可能存在一个时间点，不再学习到有用的特征，而是开始过拟合训练集。为了避免这样，防止差的泛化，当开始过拟合时我们要能够停止训练过程。为了实现这些，我们把训练过程分成epoch。epoch是在整个训练集上的单次迭代。就是说，如果我们有大小为d的训练集，用块大小为b的mini-batch梯度下降，每个epoch相当于d/b次模型更新。在每次epoch结束时，我们要测量模型的泛化如何。为实现这个操作，额外使用一个验证集，如图2-13所示。在epoch结尾，验证集将会告诉我们模型在未见过的数据上表现如何。如果训练集的准确率持续上升，同时验证集上的准确率保持不变(或者下降)，这表明到停止训练的时候了，因为我们在过拟合了。

在超参数优化过程中，验证集作为准确率的间接测量也是有用的。到目前为止，在讨论中我们已经阐述了几个超参数(学习率，minibatch大小等)，但还没开发出如何找到这些超参数的最优值的框架。找到超参数最优设置的一个有效方法是应用网格搜索(grid search)，为每个超参数选择一组有限数量的可选值(例如 $\epsilon \in${0.001, 0.01, 0.1}, batch大小 $\in$ {16， 64， 128})，然后用每一组可能的超参数选择组合训练模型。我们挑选在验证集上性能最好的超参数组合，报告使用最佳参数组合的训练模型在测试集上的准确率 $^{[4]}$。

![In deep learning we often include a validation set to prevent overfitting during the training process](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-13.png?raw=true)

图2-13 In deep learning we often include a validation set to prevent overfitting during the training process

在继续描述各种直接应付过拟合的方法之前，请将此谨记心中。下面概述创建和训练深度学习模型时使用的工作流，图2-14详细描绘了它。工作流虽然有点复杂，但它对于理解确保我们正确训练神经网络的管道至关重要。

首先我们严格定义问题，包括确定输入、可能的输出及两者的向量化表示。例如，我们的目标是训练识别癌症的深度学习模型。输入可能是张RGB图片，可以表示为像素值的向量。输出会是三种互斥可能性上的概率分布：1)正常，2)良性肿瘤(尚未转移的癌症)，或者3)恶性肿瘤(已经转移到其他器官的癌症)。

在定义好问题之后，需要创建神经网络架构来解决它。输入层应该有适当的大小来接收图像的原始数据，输出层将是大小为3的softmax。还要定义网络的中间架构(隐藏层的数量，连接情况等)。在第四章谈到卷积神经网络时，我们会进一步讨论图像识别模型的架构。此时，我们要收集大量的数据用于训练或者建模。这些数据很可能是已经被医学专家打好标签的尺寸一致的病理图像。我们把这些数据打乱并切分为训练集，验证集和测试集。

![Detailed workflow for training and evaluating a deep learning model](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-14.png?raw=true)

图2-14 Detailed workflow for training and evaluating a deep learning model

最后，我们准备开始梯度下降。在训练集上每次一个epoch训练模型，在每次epoch结尾，我们要确保训练集和验证集上的误差在减少。当其中一个的性能不再改善，我们终止训练以确保模型在测试数据上获得令人高兴的性能。如果对模型不满意，我们需要重新思考架构或者想想收集到的数据是否有做出我们感兴趣的预测的必要信息。如果训练集误差不再改善，我们可能需要更好地在数据中捕捉重要的特征。如果验证集误差不再改善，我们可能要采取措施防止过拟合。

然而，如果我们对模型在训练数据上的性能很满意，那么就可以在测试数据上测量它的性能，这些测试数据是模型在此之前从未见过的。如果模型在测试数据上表现不佳，我们需要数据集中包含更多的数据，因为看起来测试集包含的实例类型没有在训练集中得到很好的体现。如果模型在测试数据上表现良好，那么我们的工作完美完成！

> [4]: Nelder, John A., and Roger Mead. “A simplex method for function minimization.” The Computer Journal 7.4(1965): 308-313.
