## 测试集，验证集和过拟合
人工神经网络一个主要的问题是模型太复杂。例如，考虑一个神经网络从MNIST数据库(28×28像素)里的图像拉取数据，输入到有30个神经元的两个隐藏层，最后到达10个神经元的softmax层。网络里总共有近25000个参数，这样是有问题的，为了明白为什么这么说，让我们看一下图2-8展示的一个新的简单案例。

![Two potential models that might describe our dataset: a linear model versus a degree 12 polynomial](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-8.png)

图2-8 Two potential models that might describe our dataset: a linear model versus a degree 12 polynomial

我们在平面上生成了大量是数据点，目标是找到一条曲线可以最好地描述这个数据集(即，允许我们根据x坐标预测出新的数据点的y坐标)。用这些数据我们训练出两个不同的模型：一个线性模型和一个12次多项式。究竟哪条曲线值得我们信赖呢？是几乎没有预测出正确点的直线？还是预测中了数据集中每个点的复杂曲线呢？此刻我们可能相信线性拟合，因为它看起来更少勉强的味道。但为了确保我们的选择，向数据集中加入更多的数据。结果如图2-9所示。

![Evaluating our model on new data indicates that the linear fit is a much better model than the degree 12 polynomial](https://github.com/lucasbyAI/Fundamental_of_Deep_Learning_ZH/blob/master/images_folder/Fig2-9.png)

图2-9 Evaluating our model on new data indicates that the linear fit is a much better model than the degree 12 polynomial

现在决定已经很清楚了：线性模型不仅主观上感觉更好，而且定量分析也好(用平方差度量测量)。但这导致了一个非常有趣的关于训练和评估机器学习模型的讨论点。通过创建极其复杂的模型，非常容易完美地拟合训练数据集，因为我们可以给模型足够的自由度来扭曲它们去拟合训练集里的观察点。但当我们在新数据上评估如此复杂的模型时，它的性能表现很差。换句话说，模型泛化性能不好。这种现象我们称之为过拟合，它是机器学习工程师必须应对的巨大挑战之一。在深度学习中，神经网络有大量包含很多神经元的层，过拟合变成了甚至更加严峻的问题。这些模型里连接的数量都是天文数字，达到上百万个。因此，过拟合是普遍的。

让我们看看过拟合在神经网络里是什么样的。假设有个神经网络，两个输入，2维的softmax输出，隐藏层分别有3,6和20个神经元。用mini-batch梯度下降(batch大小为10)训练这些网络，结果用ConvNetJS可视化，如图2-10所示。
